{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART - 1 : CAPTURING FACE DATA OF USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade classifiers are basically used for face features detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets extract the features of face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_ext(img):\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)     # As the image captured will be coloured , we need to convert it into grayscale\n",
    "    faces=face_classifier.detectMultiScale(gray,1.3,5)      # (1.3)== scaling factor, (5) == minimum neighbours  # lies from 3 to 6,low means low accuracy\n",
    "    \n",
    "    if faces is():     # if face has no value it will return none\n",
    "        return None\n",
    "    \n",
    "    for(x,y,w,h) in faces:       # if face has some value then capture the cordinates   x,y,height,width\n",
    "        cropped_faces=img[y:y+h,x:x+w]    # we gonna capture the face from original image(img) by cordinates given by cascade classfier(faces)\n",
    "    \n",
    "    return cropped_faces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture=cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a loop to capture user face\n",
    "\n",
    "count=0\n",
    "while True:\n",
    "    ret,frame=capture.read()     # capturing the image from camera\n",
    "    \n",
    "    if face_ext(frame) is not None:     #  if the frame is not empty\n",
    "        count=count+1     # keeping a count \n",
    "        \n",
    "        # now we want the size of camera equal to size of our face\n",
    "        face=cv2.resize(face_ext(frame),(200,200))\n",
    "        face=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)    # conveting the image to grayscale\n",
    "        \n",
    "        # Saving the captured faces to a folder\n",
    "        file_name_path=\"G:/Datasets/OpenCv/my_face_data/Tarun\"+str(count)+\".JPG\"\n",
    "        \n",
    "        cv2.imwrite(file_name_path,face)\n",
    "        \n",
    "        # to keep track of number of images\n",
    "        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_DUPLEX,1,(0,255,0),2)\n",
    "        \n",
    "        # To show the faces\n",
    "        cv2.imshow(\"Face Cropper\",face)\n",
    "    \n",
    "    else:\n",
    "        print(\"FACE NOT FOUND : PLEASE ADJUST FACE OR CAMERA\")\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1)==13 or count==200:    # To break the loop when Enter key is pressed or 150 images collected\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Face Sample Collection Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART - 2 : TRAINING THE MODEL ON CAPTURED FACE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import path\n",
    "from os import listdir                   # list dir is used to fetch data from directory\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data path\n",
    "data_dir=\"G:/Datasets/OpenCv/my_face_data/\"     # remember to add \"/\" at the end or images will be empty\n",
    "\n",
    "\n",
    "myfiles=[f for f in listdir(data_dir) if isfile(join(data_dir,f))]     # List comprehension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Training images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images,train_labels=[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, files in enumerate(myfiles):\n",
    "    image_path = data_dir + myfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    train_images.append(np.asarray(images, dtype=np.uint8))\n",
    "    train_labels.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.face.LBPHFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained Successfully\n"
     ]
    }
   ],
   "source": [
    "model.train(np.asarray(train_images), np.asarray(train_labels))\n",
    "print(\"Model Trained Successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART - 3 : PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to detect face\n",
    "\n",
    "def face_det(img,size=0.5):\n",
    "    # converting image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "    # detecting faces\n",
    "    faces=face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    if faces is():    # if there are no faces present\n",
    "        return img,[]    # return empty image\n",
    "    \n",
    "    # setting up a loop for image ROI (region of interest) \n",
    "    for(x,y,w,h) in faces:\n",
    "        # drawing a contour on face\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        \n",
    "        # Picking up ROI from contour\n",
    "        roi=img[y:y+h,x:x+w]\n",
    "        \n",
    "        # resize the area\n",
    "        roi=cv2.resize(roi,(200,200))\n",
    "        \n",
    "        # ending up the function to return image and roi\n",
    "        return img,roi\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    #feeding the captured image to our previously built function\n",
    "    image, face = face_det(frame)\n",
    "    \n",
    "    # For error handling\n",
    "    try:        \n",
    "        \n",
    "        # converting the image into grayscale\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # prediction from model\n",
    "        result = model.predict(face)\n",
    "        \n",
    "        # to calculate confidence levels\n",
    "        if result[1] < 500:\n",
    "            confidence = int(100*(1-(result[1])/300))\n",
    "            display_string = str(confidence)+'% Confidence it is user'\n",
    "        \n",
    "        # To put it in text\n",
    "        cv2.putText(image,display_string,(100,120), cv2.FONT_HERSHEY_COMPLEX,1,(250,120,255),2)\n",
    "\n",
    "        # Checking Confidence \n",
    "\n",
    "        if confidence > 75:\n",
    "            cv2.putText(image, \"ACCESS GRANTED\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.imshow('Face Cropper', image)\n",
    "\n",
    "        else:\n",
    "            cv2.putText(image, \"ACCESS DENIED\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.imshow('Face Cropper', image)\n",
    "\n",
    "\n",
    "    # Now we will handle if there is no face in the screen\n",
    "    except:\n",
    "        cv2.putText(image, \"ADJUST CAMERA\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.imshow('Face Cropper', image)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # Condition to close program\n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ----------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
